{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install ucimlrepo\n",
        "\n",
        "\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "cdc_diabetes_health_indicators = fetch_ucirepo(id=891)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = cdc_diabetes_health_indicators.data.features\n",
        "y = cdc_diabetes_health_indicators.data.targets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVWHbBhjgi9T",
        "outputId": "c388c2ea-1c1a-4ddf-a24c-88245114babc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ucimlrepo in /usr/local/lib/python3.12/dist-packages (0.0.7)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2025.10.5)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "\n",
        "df_X = pd.DataFrame(X)\n",
        "\n",
        "df_y = pd.DataFrame(y)\n",
        "\n",
        "y_1D = df_y.squeeze()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_X, y_1D, test_size=0.3,\n",
        "                                                    random_state=42, stratify=y_1D)\n",
        "X_train_scaled = (X_train - X_train.mean()) / X_train.std(ddof=0)\n",
        "\n",
        "X_test_scaled = (X_test - X_train.mean()) / X_train.std(ddof=0)\n",
        "\n",
        "#print(df_y.isnull().sum())\n",
        "\n",
        "clf = LogisticRegression(\n",
        "    solver=\"lbfgs\", max_iter=1000\n",
        ")\n",
        "clf.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred  = clf.predict(X_test_scaled)\n",
        "y_proba = clf.predict_proba(X_test_scaled)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRqQ5z7eeRik",
        "outputId": "70903dfe-c727-4204-d3ba-1e4c8b454a1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.863252917060864\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.98      0.92     65500\n",
            "           1       0.53      0.16      0.24     10604\n",
            "\n",
            "    accuracy                           0.86     76104\n",
            "   macro avg       0.70      0.57      0.58     76104\n",
            "weighted avg       0.83      0.86      0.83     76104\n",
            "\n",
            "[[64027  1473]\n",
            " [ 8934  1670]]\n"
          ]
        }
      ]
    }
  ]
}