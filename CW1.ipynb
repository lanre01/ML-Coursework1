{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Fi7CKjSgMmEZ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import seaborn as sns\n",
        "import scipy\n",
        "from scipy.stats import pearsonr\n",
        "import sklearn\n",
        "from sklearn import datasets, linear_model\n",
        "from sklearn import preprocessing\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.tree import DecisionTreeRegressor, plot_tree, DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPRegressor\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification"
      ],
      "metadata": {
        "id": "nFglrySlOgFD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"diabetes_binary_5050split_health_indicators_BRFSS2015.csv\")\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "gyhFACBFPHMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()\n",
        "df.describe()\n",
        "df['Diabetes_binary'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "U0g9stTQPAt3",
        "outputId": "96fa2bf8-3f5b-480c-f8ea-2917dde44553"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1875488751.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Diabetes_binary'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "df[numeric_cols].hist(figsize=(12,10), bins=20, edgecolor='black')\n",
        "plt.suptitle('Feature Distributions', fontsize=14)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6ZjZmozYRDHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14, 8))\n",
        "for i, col in enumerate(numeric_cols[:6], 1):\n",
        "    plt.subplot(2, 3, i)\n",
        "    sns.boxplot(y=df[col], color='skyblue')\n",
        "    plt.title(f'Boxplot of {col}')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SRQgy8_nRH3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression"
      ],
      "metadata": {
        "id": "VOppgwL2OmBW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Split\n",
        "X = df.drop(\"Diabetes_binary\", axis=1)\n",
        "y = df[\"Diabetes_binary\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# 2) Pipeline = scaling + logistic regression\n",
        "pipe = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"clf\", LogisticRegression(solver=\"lbfgs\", max_iter=1000))\n",
        "])\n",
        "\n",
        "# 3) K-fold CV\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_scores = cross_val_score(pipe, X, y, cv=cv, scoring=\"accuracy\")\n",
        "\n",
        "print(\"Cross-validation scores:\", cv_scores)\n",
        "print(\"Mean CV accuracy: %.3f ± %.3f\" % (cv_scores.mean(), cv_scores.std()))\n",
        "\n",
        "# 4) Fit on train and test\n",
        "pipe.fit(X_train, y_train)\n",
        "y_pred = pipe.predict(X_test)\n",
        "\n",
        "print(\"Test Accuracy: %.3f\" % accuracy_score(y_test, y_pred))\n",
        ""
      ],
      "metadata": {
        "id": "PNF-lm6qOkcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decision Tree"
      ],
      "metadata": {
        "id": "YgfatxEhPUte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(df[TARGET_COL].value_counts())\n",
        "\n",
        "TARGET_COL = 'Diabetes_binary'\n",
        "SEED = 42\n",
        "\n",
        "X = df.drop(TARGET_COL, axis=1)\n",
        "y = df[TARGET_COL]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=SEED\n",
        ")\n",
        "\n",
        "X_train.shape, X_test.shape\n",
        "\n",
        "\n",
        "((56553, 21), (14139, 21))\n",
        "\n",
        "\n",
        "clf = DecisionTreeClassifier(\n",
        "    criterion='gini',\n",
        "    max_depth=None,\n",
        "    min_samples_split=2,\n",
        "    min_samples_leaf=1,\n",
        "    random_state=SEED\n",
        ")\n",
        "\n",
        "\n",
        "cv = KFold(n_splits=10, shuffle=True, random_state=SEED)\n",
        "cv_scores = cross_val_score(clf, X, y, cv=cv, scoring='accuracy')\n",
        "\n",
        "print(\"Cross-validation scores:\", cv_scores)\n",
        "print(\"Mean CV accuracy: %.4f ± %.4f\" % (cv_scores.mean(), cv_scores.std()))\n",
        "\n"
      ],
      "metadata": {
        "id": "xjSadk1aPfB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "viz_depth = 3\n",
        "plt.figure(figsize=(14, 8))\n",
        "plot_tree(\n",
        "    clf,\n",
        "    feature_names=X.columns,\n",
        "    class_names=[str(c) for c in sorted(y.unique())],\n",
        "    max_depth=viz_depth,\n",
        "    filled=True,\n",
        "    fontsize=8\n",
        ")\n",
        "plt.title(f\"Decision Tree (max_depth visualized = {viz_depth})\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qjEEzEYuQS72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Support Vector Machine"
      ],
      "metadata": {
        "id": "tl53wfA0QeLf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset into testing and training\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "# Perform feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Run the model\n",
        "Svm_model = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)\n",
        "Svm_model.fit(X_train_scaled, y_train)\n",
        "y_pred = Svm_model.predict(X_test_scaled)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "CFyu-OcQRY1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# K-Fold Cross Validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "scores = cross_val_score(Svm_model, X, y, cv=kf, scoring='accuracy')\n",
        "\n",
        "print(\"Cross-validation scores:\", scores)\n",
        "print(\"Mean CV accuracy:\", np.mean(scores))"
      ],
      "metadata": {
        "id": "O1NXbd04Rsx6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multi-Layer Perceptron Neural Network"
      ],
      "metadata": {
        "id": "o7Ss7B2-R6_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Stratified train-test split (70/30)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Build a pipeline\n",
        "mlp_pipeline = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    MLPClassifier(hidden_layer_sizes=(10,), activation='relu',\n",
        "                  solver='adam', random_state=1, max_iter=300)\n",
        ")\n",
        "\n",
        "# Cross-validation\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_scores = cross_val_score(mlp_pipeline, X, y, cv=cv, scoring=\"accuracy\")\n",
        "\n",
        "print(\"Cross-validation scores:\", cv_scores)\n",
        "print(\"Mean CV accuracy: %.3f ± %.3f\" % (cv_scores.mean(), cv_scores.std()))\n",
        "\n",
        "# Fit and test accuracy\n",
        "mlp_pipeline.fit(X_train, y_train)\n",
        "y_pred = mlp_pipeline.predict(X_test)\n",
        "print(\"Test Accuracy: %.3f\" % accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "RF6jV6vMSEtO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regression\n"
      ],
      "metadata": {
        "id": "DeY5ZpEyMtdp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('winequality-red.csv', sep=';', index_col=False)\n",
        "data.head()"
      ],
      "metadata": {
        "id": "ny7ZDoWtMsHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preprocessing\n",
        "# desribe the data\n",
        "data.describe() # column with possible outliers - free sulphur dioxide, total sulfur dioxide, residual sugar,\n",
        "# Use box plot to check the value range\n",
        "data_mean = data.iloc[:, :]\n",
        "data_mean.plot(kind='box', subplots=True, layout=(8,4), sharex=False,\n",
        "sharey=False, fontsize=12, figsize=(15,20));"
      ],
      "metadata": {
        "id": "4ldYRQ0CNKeA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare the features data ranges\n",
        "fig,ax=plt.subplots(1,figsize=(20,8))\n",
        "sns.boxplot(data=data.iloc[:, 1:12],ax=ax)"
      ],
      "metadata": {
        "id": "Gqm-8DKrNNMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Normalisation\n",
        "X = data.drop('quality', axis=1)\n",
        "y = data['quality'].values.reshape(-1, 1)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "fig,ax=plt.subplots(1,figsize=(20,8))\n",
        "sns.boxplot(data=X_scaled,ax=ax)\n",
        "\n",
        "X_biased = np.c_[X_scaled, np.ones((X_scaled.shape[0], 1))]"
      ],
      "metadata": {
        "id": "TTdgsJGpNQ2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Linear Regression"
      ],
      "metadata": {
        "id": "TuoGf8vyNasr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = 0.1\n",
        "max_iterations = 1000\n",
        "m, n = X_biased.shape\n",
        "\n",
        "# Gradient Descent\n",
        "def gradient_descent(X, y, alpha, max_iterations, shape):\n",
        "    m, n = shape\n",
        "    w = np.random.randn(n, 1)\n",
        "\n",
        "    for iteration in range(max_iterations):\n",
        "        gradients = (2/m) * X.T.dot(X.dot(w) - y)\n",
        "        w = w - alpha * gradients\n",
        "\n",
        "    return w\n",
        "\n",
        "# K-Fold Cross Validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=15)\n",
        "mse_scores = []\n",
        "\n",
        "\n",
        "for train_index, val_index in kf.split(X_biased):\n",
        "    X_train, X_val = X_biased[train_index], X_biased[val_index]\n",
        "    y_train, y_val = y[train_index], y[val_index]\n",
        "\n",
        "    w = gradient_descent(X_train, y_train, alpha, max_iterations, X_train.shape)\n",
        "    y_predicted = np.round(np.array(X_val).dot(w))\n",
        "    mse = mean_squared_error(y_val, y_predicted)\n",
        "    mse_scores.append(mse)\n",
        "\n",
        "\n",
        "print(\"Average MSE:\", np.mean(mse_scores))\n"
      ],
      "metadata": {
        "id": "xqVxcCtlNcxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Support Vector Machine"
      ],
      "metadata": {
        "id": "_BeLx3zONkd-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kf = KFold(n_splits=5, shuffle=True, random_state=15)\n",
        "mse_scores = []\n",
        "\n",
        "for train_index, val_index in kf.split(X_scaled):\n",
        "    X_train, X_val = X_scaled[train_index], X_scaled[val_index]\n",
        "    y_train, y_val = y[train_index], y[val_index]\n",
        "\n",
        "    # Initialize and train SVM regressor\n",
        "    svr_model = SVR(kernel='rbf', C=1.0, epsilon=0.1)\n",
        "    svr_model.fit(X_train, y_train.ravel())  # .ravel() flattens y to 1D\n",
        "    # Predict and evaluate\n",
        "    y_pred = np.round(svr_model.predict(X_val))\n",
        "    mse = mean_squared_error(y_val, y_pred)\n",
        "    mse_scores.append(mse)\n",
        "\n",
        "print(\"Average MSE (SVR):\", np.mean(mse_scores))"
      ],
      "metadata": {
        "id": "BNGfjlC-NtCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decision Tree"
      ],
      "metadata": {
        "id": "iQVQb7xfN927"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up K-Fold\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=15)\n",
        "mse_scores = []\n",
        "\n",
        "\n",
        "for train_index, val_index in kf.split(X):\n",
        "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
        "    y_train, y_val = y[train_index], y[val_index]\n",
        "\n",
        "\n",
        "    # Initialize and train Decision Tree Regressor\n",
        "    dt_model = DecisionTreeRegressor(max_depth=5, random_state=15)\n",
        "    dt_model.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = np.round(dt_model.predict(X_val))\n",
        "    mse = mean_squared_error(y_val, y_pred)\n",
        "    mse_scores.append(mse)\n",
        "\n",
        "print(\"Average MSE (Decision Tree):\", np.mean(mse_scores))"
      ],
      "metadata": {
        "id": "BqS-yPxfOAJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multi-Layer Perceptron Neural Network"
      ],
      "metadata": {
        "id": "DzHIH_y4OEeX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kf = KFold(n_splits=5, shuffle=True, random_state=15)\n",
        "mse_scores = []\n",
        "\n",
        "for train_index, val_index in kf.split(X_scaled):\n",
        "    X_train, X_val = X_scaled[train_index], X_scaled[val_index]\n",
        "    y_train, y_val = y[train_index], y[val_index]\n",
        "\n",
        "    # Initialize and train MLP Regressor\n",
        "    mlp_model = MLPRegressor(hidden_layer_sizes=(100,), activation='relu', solver='adam',\n",
        "                             max_iter=500, random_state=15)\n",
        "    mlp_model.fit(X_train, y_train.ravel())\n",
        "\n",
        "    # Predict and evaluate\n",
        "    y_pred = np.round(mlp_model.predict(X_val))\n",
        "    mse = mean_squared_error(y_val, y_pred)\n",
        "    mse_scores.append(mse)\n",
        "\n",
        "print(\"Average MSE (MLP):\", np.mean(mse_scores))"
      ],
      "metadata": {
        "id": "K43EDoMcOKbJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}